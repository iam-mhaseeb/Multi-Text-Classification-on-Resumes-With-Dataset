{"cells":[{"metadata":{"_uuid":"adbd9e374e28f016c769d3af38b7aa79ed747d16"},"cell_type":"markdown","source":"**Problem Formulation**\n\nThe problem is supervised text classification problem, and our goal is to investigate which supervised machine learning methods are best suited to solve it.\n\nWe have 25 unique resume categories to classify. This is multi-class text classification problem. I can’t wait to see what we can achieve!"},{"metadata":{"_uuid":"2d3fee7b7c17791ff2b77c88adee067edcf82f6d"},"cell_type":"markdown","source":"**Data Exploration**\n\nBefore diving into training machine learning models, we should look into our data to know what exactly is our data:"},{"metadata":{"trusted":true,"_uuid":"88b6179380f321a3a06b2c1e8b519c900135cf7a"},"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('../input/resume_dataset.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"**Data Cleaning**\n\nWe will remove missing values , and add a column encoding the Category as an integer because categorical variables are often better represented by integers than strings.\n\nWe also create a couple of dictionaries for future use.\n\nAfter cleaning up, this is the first five rows of the data we will be working on:"},{"metadata":{"trusted":true,"_uuid":"ebbd458c71d5b78548721af7206bfafef3ec5e69"},"cell_type":"code","source":"from io import StringIO\ncol = ['Category', 'Resume']\ndf = df[col]\ndf = df[pd.notnull(df['Resume'])]\ndf.columns = ['Category', 'Resume']\ndf['category_id'] = df['Category'].factorize()[0]\ncategory_id_df = df[['Category', 'category_id']].drop_duplicates().sort_values('category_id')\ncategory_to_id = dict(category_id_df.values)\nid_to_category = dict(category_id_df[['category_id', 'Category']].values)\ndf","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c91470bb49f860268c8c9950b62a0841bc0f4bbe"},"cell_type":"markdown","source":"**Imbalanced Classes**\n\nWe see that the number of Categories is imbalanced. Resumes  are more biased towards to few Categories."},{"metadata":{"trusted":true,"_uuid":"fc2e577710c435590c81ef2a731a0cd318357eb7"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig = plt.figure(figsize=(8,6))\ndf.groupby('Category').Resume.count().plot.bar(ylim=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"77b623d760b91eaba486985186afd9f9e380d881"},"cell_type":"markdown","source":"When we encounter such problems, we are bound to have difficulties solving them with standard algorithms. Conventional algorithms are often biased towards the majority class, not taking the data distribution into consideration. In the worst case, minority classes are treated as outliers and ignored. For some cases, such as fraud detection or cancer prediction, we would need to carefully configure our model or artificially balance the dataset, for example by undersampling or oversampling each class.\n\nHowever, in our case of learning imbalanced data, the majority classes might be of our great interest. It is desirable to have a classifier that gives high prediction accuracy over the majority class, while maintaining reasonable accuracy for the minority classes. Therefore, we will leave it as it is."},{"metadata":{"_uuid":"db7a00355d253f7ca9d05bbbc29d5ac97e90b9a9"},"cell_type":"markdown","source":"**Text Representation**\n\nThe classifiers and learning algorithms can not directly process the text documents in their original form, as most of them expect numerical feature vectors with a fixed size rather than the raw text documents with variable length. Therefore, during the preprocessing step, the texts are converted to a more manageable representation.\n\nOne common approach for extracting features from text is to use the bag of words model: a model where for each document, a complaint narrative in our case, the presence (and often the frequency) of words is taken into consideration, but the order in which they occur is ignored.\n\nSpecifically, for each term in our dataset, we will calculate a measure called Term Frequency, Inverse Document Frequency, abbreviated to tf-idf. We will use sklearn.feature_extraction.text.TfidfVectorizer to calculate a tf-idf vector for each of Resume."},{"metadata":{"trusted":true,"_uuid":"5df9ec6731a5694d832478d7689324e4fc1a2aab"},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\nfeatures = tfidf.fit_transform(df.Resume).toarray()\nlabels = df.category_id\nfeatures.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea7f503483323ba26cd031e162c18aa647961b1f"},"cell_type":"markdown","source":"Now, each of 1219 Resumes is represented by 27968 features, representing the tf-idf score for different unigrams and bigrams.\nWe can use sklearn.feature_selection.chi2 to find the terms that are the most correlated with each of the Category:"},{"metadata":{"trusted":true,"_uuid":"080a9c9886df0b1982d0e0c881e3a207a38e7439"},"cell_type":"code","source":"from sklearn.feature_selection import chi2\nimport numpy as np\nN = 2\nfor Category, category_id in sorted(category_to_id.items()):\n  features_chi2 = chi2(features, labels == category_id)\n  indices = np.argsort(features_chi2[0])\n  feature_names = np.array(tfidf.get_feature_names())[indices]\n  unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n  bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n  print(\"# '{}':\".format(Category))\n  print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-N:])))\n  print(\"  . Most correlated bigrams:\\n. {}\".format('\\n. '.join(bigrams[-N:])))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9bc455f837369345d3180451f944cde44eb7b33a"},"cell_type":"markdown","source":"They all make sense, don’t you think so?\nTill some extend machine learned to recognize what's more related to a job Category.\nIsn't that great?"},{"metadata":{"_uuid":"125227db6ca205e1abb8dcb3d82afdc86a386c6b"},"cell_type":"markdown","source":"**Multi-Class Classifier: Features and Design**\n\nTo train supervised classifiers, we first transformed the “Resumes” into a vector of numbers. We explored vector representations such as TF-IDF weighted vectors.\nAfter having this vector representations of the text we can train supervised classifiers to train unseen “Resumes” and predict the “Job Category” on which they fall.\nAfter all the above data transformation, now that we have all the features and labels, it is time to train the classifiers. There are a number of algorithms we can use for this type of problem.\n\nNaive Bayes Classifier: the one most suitable for word counts is the multinomial variant:"},{"metadata":{"trusted":true,"_uuid":"e808663923bee34ad93d54bd1e9265c85cc95c0e","collapsed":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nX_train, X_test, y_train, y_test = train_test_split(df['Resume'], df['Category'], random_state = 0)\ncount_vect = CountVectorizer()\nX_train_counts = count_vect.fit_transform(X_train)\ntfidf_transformer = TfidfTransformer()\nX_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\nclf = MultinomialNB().fit(X_train_tfidf, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"af630a97bac6acdd75dea7e4234ca7a7c466e46e"},"cell_type":"markdown","source":"After fitting the training set, let’s make some predictions. I'm going to use raw text string resume of a software engineer to predict best class for that resume."},{"metadata":{"trusted":true,"_uuid":"f4827a825442898ea14a564124f9786903935921"},"cell_type":"code","source":"software_engineer = '''﻿Irshad Ali\nEmail Address: irshadali18@gmail.com,irshadali@outlook.com \nCell: 0321-7588568\n\nObjective\nI am looking forward to join a progressive organization. I am Strong team builder and leader. I have high level of personal morals and integrity. I am Goal oriented, self-motivated and committed to the successful outcome of the project. I am willing to work hard and have a great desire to learn.\nSummary\n    • Since March 2007, have 6 years plus of extensive hands on experience of website development.\n    • An experienced team lead and team player with excellent communication and interpersonal skills who has the ability to work independently under pressure.\n    • Currently working as Senior Software Engineer/Team Lead at Hashe Computer Solutions.\n    • Masters in 2007 from the University College of Information Technology, Lahore, Pakistan.\nSkills\nLanguages/Web Development\nPHP, C# .Net, JavaScript, HTML, CSS, Java, XML, SQL\nFrameworks\nAJAX, Zend, Symfony2,  CodeIgniter\nOpen Source\nWordpress, Joomla, XCart, CSCart\nDatabases\nMySQL, Oracle\nTools\nNetbeans, Dreamweaver, SqlYog, NavicoSoft, MicroOlap\n\n\nExperience\nHashe Computer Solution, Lahore, Pakistan \nSenior Software Engineer / Team Lead\n(March 2008 – To date)\nResponsibilities include team management, direct client communication and software development.\nMechtechnologies, Lahore, Pakistan \nSoftware Engineer\n(March 2007 – February 2008)\n\nProjects\nFreight Ordering System – Hashe Computer Solutions\nRole:\n    • Development Lead\nTools:\n    • PHP, MySQL, Ajax, JQuery , Web Services\nDetails:\n    • This is a web based system, which provides an online competitive freight quotes within zip code range from best courier & transport companies of the region with favorable discounts and transit days. Later shipment can be booked out of these quotes and tracked though website. Companies can add / manage their locations, product catalog for swift use of the system.\n    • This application works with SMC3 to acquire shipment rates for given locations and then apply different accessorial and fuel charges added by admin to calculate final shipment rates.\n    • Using the back office application, admin can set different accessorial, discounts, fuel charges, and FAK classes for each company and carrier. Manage the Sales Representatives & this commission for different companies & Carriers.\n    • Comprehensive report system provides reports about the shipment, carrier, customer, sale representative commission and billing reports. \n    • Complete Accounting System.\n\nhttp://www.freightanywhere.com\nhttp://www.tech-logistics.com\n\nOnline Golf Course Booking System – Hashe Computer Solutions\nRole:\n    • Application Developer\nTools:\n    • PHP, MySQL, Ajax, JQuery, Web Services\nDetails:\n    • This is a web based system, which provides golfers an easy way to use website to search, compare, and book golf tee times for free. With numerous golf courses available for play in most areas.\n\nhttp://www.back9booking.com\n\nEcommerce Shopping System – Hashe Computer Solutions\nRole:\n    • Application Developer/Team Lead\nTools:\n    • PHP, MySQL, JQuery, Zend\nDetails:\nComplete ecommerce shopping system with following features\n    • Administration system to easily update all product details, prices, pictures, stock details and other information online.\n    • Manage Customer Accounts\n    • Manage Wish list\n    • Customer Reviews & Rating\n    • Manage categories and products\n    • Manage Product options and related products\n    • Advanced pricing algorithms\n    • Order and Invoice history\n    • Take payments online using PayPal\n    • Shopping cart system to allow easy purchase of products\n    • Automatic email notification of orders\n    • Full checkout procedure\n    • Fast and friendly quick search and advanced search features\n    • Reports of site visits, pages viewed, most viewed products, most ordered products and most viewed categories\nhttp://www.tcig.co.uk\n\nFree Home Listing – Hashe Computer Solutions\nRole:\n    • Application Developer\nTools:\n    • PHP, MySQL, JQuery, Codeigniter\nDetails:\nThis is a property portal with three access level\n    • Customer Login\n        ◦ Search Properties by State And City, Key words and Zip Code with option in different miles radius i.e. search all properties having zip code 03055 and within 10 miles radius around it.  \n        ◦ Register as Customer\n        ◦ Manage their Listings\n        ◦ Add/Edit property\n        ◦ Add/Edit/Delete Properties Images\n        ◦ Delete Properties\n    • Agent Login\n        ◦ Add/Edit property\n        ◦ Add/Edit/Delete Properties Images\n        ◦ Delete Properties\n    • Admin login\n        ◦ Manage Customers (Add/Edit/Delete/Active/Inactive)\n        ◦ Manage Customer Packages\n        ◦ Manage Agents (Add/Edit/Delete/Active/Inactive)\n        ◦ Manage Listings (Add/Edit/Delete/Active/Inactive)\nhttp://demo.hashe.com/freehomelistings/\n\nRockingham Acres – Hashe Computer Solutions\nRole:\n    • Application Developer\nTools:\n    • PHP, MySQL, JQuery\nDetails:\nThis is an Online Flower Store has\n    • Online Shopping Cart\n    • Word Press Blog\nhttp://www.rockinghamacres.com/\n\n\nThird Coast Collection – Hashe Computer Solutions\nRole:\n    • Application Developer\nTools:\n    • PHP, MySQL, JQuery\nDetails:\nThis website has\n    • Online Shopping Cart\n    • Authorized .Net Payment Integration\n    • Word Press Blog\nhttp://www.thirdcoastcollection.com/\n\nPPA-Office Management System – Hashe Computer Solutions\nRole:\n    • Application Developer\nTools:\n    • PHP, MySQL, JQuery\nDetails:\nPPA (Pakistan Progressive Associate) is  licensed  by  Ministry   of  Labor,  Manpower  and  Overseas   Employment ,   Government of  Pakistan for recruitment  of  manpower.  So PPA-Office Management System is developed to manage & integrate all PPA internal processes (i.e. client, contracts, jobs, job seeker registration, resume bank, recruitment process, and visa & departure process). We split this big system into following modules.\n    • Office Workflow Management System Administration: This application will allow the administration to\n        ◦ Manage Companies, Contracts\n        ◦ Application Configurations\n        ◦ Manage invoices\n        ◦ Manage administrative expenses\n            ▪ Advertisement costs\n            ▪ Courier charges\n            ▪ Misc. charges to be posted\n    • Office Workflow Management System: This application will automate the recruitment process of PPA administration and will implement all the business processes hence allowing straight through processing of jobs. This application will have three separate work flows\n        ◦ Pre Processing – Jobs management, Resume management and data entry, short listing, interview scheduling and execution, selection of candidates and forwarding for post-processing. \n        ◦ Post Processing\n        ◦ Archiving\n    • Online Client / Candidate Portal: This portal will allow\n        ◦ PPA administration to manage advertisement jobs\n        ◦ PPA affiliated companies to:\n            ▪ Login into the system\n            ▪ Add jobs\n            ▪ View list of candidates forwarded by PPA administration, short list them, add notes\n            ▪ Browse/Search (if allowed) resume database, create resume lists, add notes on resumes\n        ◦ Potential candidates to:\n            ▪ Register\n            ▪ Add resumes\n            ▪ Search for jobs\n    • System will allow the printing of all documents required during the execution of a case. System will allow three types of print\n        ◦ Printing with PPA logo\n        ◦ Printing without PPA logo – to be printed on PPA letter head\n        ◦ Custom printing\n\nNetSignNews.com – Hashe Computer Solutions\nRole:\n    • Development Lead\nTools:\n    • PHP, MySQL\nDetails:\n    • Net Sign News is a specialized news channel for with hearing disabilities. NetSignNews.com is an online news portal for NetSignNews. News videos are streamed on demand using FLV format files. This application has a power administration utility using which administrator can manage the contents being published on the website.\n\nVegaPrint.co.uk – VegaSoft Technologies\nRole:\n    • Development Lead (Freelance)\nTools:\n    • PHP, MySQL\nDetails:\n    • This is print media service provider’s website. Here user can order print media products by paying online payment through PayPal, users can also track there orders online. \n    • Using the back office application, admin can add different products, services, special offers, shipment charges, manage users and orders. \n\nBug Tracking – Mechtechnologies\nRole:\n    • Development Team Member\nTools:\n    • PHP, MySQL\nDetails:\nThis is a web based application which allows software developers to track new bugs, prioritize and assign bugs to team members, generate bug reports, send email messages between users, attach files, customize the account according to their special needs and more.\n\nAcademic Projects\nStudent Information System - MIT Final Project\n    • Student Information System superior University Lahore is a web based application developed in PHP and MySQL as database.\n\n\nEducation\nPunjab University College of Information Technology, Lahore, Pakistan \nMSC Information Technology \nYear: 2007\n\nCertifications\nMicrosoft Technologies (Exam: 70-480)\nMicrosoft Certified Professional \nYear: 2013\nMicrosoft Technologies (C# .Net)\nEVS Lahore \nYear: 2013\n\nInterests\nComputer Gaming\nReferences\nReferences can be provided on request.'''\nprint(clf.predict(count_vect.transform([software_engineer])))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"65307cb54ecaf951ae7ad1a3666d73a73db488c4"},"cell_type":"markdown","source":"Isn't it awesome? "},{"metadata":{"_uuid":"191f37e6fac7925c7072a11a8561a02fcaf6daa2"},"cell_type":"markdown","source":"**Model Selection**\n\nWe are now ready to experiment with different machine learning models, evaluate their accuracy and find the source of any potential issues.\n\nWe will benchmark the following four models:\n\n* Logistic Regression\n* (Multinomial) Naive Bayes\n* Linear Support Vector Machine\n* Random Forest"},{"metadata":{"trusted":true,"_uuid":"7057c7a6c775cb3cb18c8090f1f9cd683c8f7a04"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.model_selection import cross_val_score\nmodels = [\n    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n    LinearSVC(),\n    MultinomialNB(),\n    LogisticRegression(random_state=0),\n]\nCV = 5\ncv_df = pd.DataFrame(index=range(CV * len(models)))\nentries = []\nfor model in models:\n  model_name = model.__class__.__name__\n  accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)\n  for fold_idx, accuracy in enumerate(accuracies):\n    entries.append((model_name, fold_idx, accuracy))\ncv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\nimport seaborn as sns\nsns.boxplot(x='model_name', y='accuracy', data=cv_df)\nsns.stripplot(x='model_name', y='accuracy', data=cv_df, \n              size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d97f174712f5f47ae12203538acd8925cc54a6ae"},"cell_type":"code","source":"cv_df.groupby('model_name').accuracy.mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"46ebd00e781d2c33610ff006333ebbfc99e246da"},"cell_type":"markdown","source":"LinearSVC and Logistic Regression perform better than the other two classifiers, with LinearSVC having a slight advantage with a median accuracy of around 65-72%."},{"metadata":{"_uuid":"ed315f978e98d8d38ea77e38057acc710901b918"},"cell_type":"markdown","source":"**Model Evaluation**\nContinue with our best model (LinearSVC), we are going to look at the confusion matrix, and show the discrepancies between predicted and actual labels.\n"},{"metadata":{"trusted":true,"_uuid":"accc8c4cdd01b55fb36c3d1a7c1de02e1be626e8"},"cell_type":"code","source":"model = LinearSVC()\nX_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(features, labels, df.index, test_size=0.33, random_state=0)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nfrom sklearn.metrics import confusion_matrix\nconf_mat = confusion_matrix(y_test, y_pred)\nfig, ax = plt.subplots(figsize=(10,10))\nsns.heatmap(conf_mat, annot=True, fmt='d',\n            xticklabels=category_id_df.Category.values, yticklabels=category_id_df.Category.values)\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"427366d20402289d86b58cc2258fc88611870638"},"cell_type":"markdown","source":"The vast majority of the predictions end up on the diagonal (predicted label = actual label), where we want them to be.\nFinally, we print out the classification report for each class:"},{"metadata":{"trusted":true,"_uuid":"cfc0f618151a22c3ed8bb9c229f2ca0592799e99"},"cell_type":"code","source":"from sklearn import metrics\nprint(metrics.classification_report(y_test, y_pred, target_names=df['Category'].unique()))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}